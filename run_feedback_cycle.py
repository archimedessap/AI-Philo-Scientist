#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
run_feedback_cycle.py
====================
ä¸€æ¬¡æ€§æ‰§è¡Œ"ç†è®ºç”Ÿæˆ â†’ è¯„ä¼° â†’ æ·±åº¦å¯¹è¯ä¼˜åŒ–"å¤šä»£å¾ªç¯ã€‚

æµç¨‹ (æ¯ä»£)ï¼š
1. è°ƒç”¨ run_full_cycle.py ç”Ÿæˆæ–°ç†è®ºå¹¶è¯„ä¼°ï¼Œå¾—åˆ° main_run_dir
2. è°ƒç”¨ run_m3_auto_refinement.py å¯¹ Top-N ç†è®ºåšæ·±åº¦ä¼˜åŒ–
3. å°†ä¼˜åŒ–åç†è®ºæ”¶é›†åˆ° next_theory_pool/ï¼Œä½œä¸ºä¸‹ä¸€ä»£åˆæˆçš„è¾“å…¥

é»˜è®¤ä»…æŠŠ"æœ€ä½³è¿­ä»£ç‰ˆæœ¬"å¼•å›ï¼›è‹¥æ—  JSON é€šè¿‡ Schema æ ¡éªŒï¼Œåˆ™ä¿ç•™åŸç‰ˆæœ¬ã€‚
"""

from __future__ import annotations
import subprocess
import sys
import argparse
from pathlib import Path
import json
import shutil
import glob
import time

# -----------------------------------------------------------------------------
# å·¥å…·å‡½æ•°
# -----------------------------------------------------------------------------

def run_cmd(cmd: list[str]):
    """ç®€æ˜“åŒæ­¥æ‰§è¡Œï¼Œå‡ºé”™å³é€€å‡ºã€‚"""
    print("\n$ " + " ".join(cmd))
    res = subprocess.call(cmd)
    if res != 0:
        print(f"[FATAL] å‘½ä»¤å¤±è´¥: {' '.join(cmd)}")
        sys.exit(res)


def find_unique(glob_pattern: str) -> Path:
    """ç¡®ä¿åªæ‰¾åˆ°ä¸€ä¸ªæ–‡ä»¶/ç›®å½•"""
    matches = glob.glob(glob_pattern)
    if not matches:
        raise FileNotFoundError(f"æœªæ‰¾åˆ°åŒ¹é…: {glob_pattern}")
    if len(matches) > 1:
        raise RuntimeError(f"åŒ¹é…åˆ°å¤šä¸ªè·¯å¾„: {matches}")
    return Path(matches[0])


def collect_improved_theories(depth_runs_dir: Path, dest_dir: Path):
    """éå† depth_runsï¼Œæ¯æ¡ç†è®ºæŒ‘é€‰æœ€ç»ˆè¿­ä»£çš„ improved_*.json å¤åˆ¶åˆ° dest_dir"""
    from tools.refinement.schema_validator import is_valid_theory_json

    dest_dir.mkdir(parents=True, exist_ok=True)

    for theory_dir in depth_runs_dir.iterdir():
        if not theory_dir.is_dir():
            continue
        # æ‰¾åˆ°æœ€åä¸€è½® iter_*
        iter_dirs = sorted([p for p in theory_dir.iterdir() if p.is_dir() and p.name.startswith("iter_")],
                           key=lambda p: int(p.name.split("_")[1]))
        if not iter_dirs:
            continue
        last_iter = iter_dirs[-1]
        # ä¼˜å…ˆå– improved_*.json
        improved_files = list(last_iter.glob("improved_*.json"))
        source_json = None
        if improved_files:
            source_json = improved_files[0]
        else:
            # fallback to origin in iter_0 or work_dir root
            origin = theory_dir / "iter_0" / source_json if False else None  # placeholder
        if source_json is None:
            continue
        # æ ¡éªŒ
        with open(source_json, "r", encoding="utf-8") as f:
            data = json.load(f)
        if not is_valid_theory_json(data):
            continue
        shutil.copy(source_json, dest_dir / source_json.name)

# -----------------------------------------------------------------------------
# ä¸»æµç¨‹
# -----------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser("å¤šä»£åé¦ˆå¾ªç¯æ§åˆ¶è„šæœ¬")
    parser.add_argument("--generations", type=int, default=2, help="å¾ªç¯ä»£æ•°")
    parser.add_argument("--initial_theories_dir", type=str, default="data/theories_v2.1", help="åˆå§‹ç†è®ºæ± ç›®å½•")
    parser.add_argument("--output_root", type=str, default="data/feedback_runs", help="æ€»è¾“å‡ºæ ¹ç›®å½•")

    # é€ä¼ å¸¸ç”¨å‚æ•°
    parser.add_argument("--synthesis_model_source", default="google")
    parser.add_argument("--synthesis_model_name",   default="gemini-1.5-pro-latest")
    parser.add_argument("--evaluation_model_source", default="deepseek")
    parser.add_argument("--evaluation_model_name",   default="deepseek-reasoner")
    parser.add_argument("--top_n", type=int, default=5)
    parser.add_argument("--max_iters", type=int, default=2)
    parser.add_argument("--min_improve", type=float, default=0.03)

    args = parser.parse_args()

    base_root = Path(args.output_root)
    base_root.mkdir(parents=True, exist_ok=True)

    theories_dir_for_next = Path(args.initial_theories_dir).resolve()

    for gen in range(1, args.generations + 1):
        print("\n" + "="*80)
        print(f"ğŸŒ€ Generation {gen}")
        print("="*80)
        gen_dir = base_root / f"generation_{gen}"
        gen_dir.mkdir(parents=True, exist_ok=True)

        # ------------------------------------------------------------------
        # Phase 1: run_full_cycle
        # ------------------------------------------------------------------
        full_cycle_dir = gen_dir / "full_cycle"
        cmd_full = [
            "python", "run_full_cycle.py",
            "--existing_theories_dir", str(theories_dir_for_next),
            "--base_output_dir", str(full_cycle_dir),
            "--max_pairs_to_analyze", "5",
            "--variants_per_contradiction", "2",
            "--synthesis_model_source", args.synthesis_model_source,
            "--synthesis_model_name", args.synthesis_model_name,
            "--evaluation_model_source", args.evaluation_model_source,
            "--evaluation_model_name", args.evaluation_model_name
        ]
        run_cmd(cmd_full)

        # æ‰¾åˆ° run_* ç›®å½•
        run_subdir = find_unique(str(full_cycle_dir / "run_*/"))

        # ------------------------------------------------------------------
        # Phase 2: run_m3_auto_refinement
        # ------------------------------------------------------------------
        summary_file = find_unique(str(run_subdir / "2_evaluation_output" / "*/final_evaluation_summary.json"))
        theories_root = find_unique(str(run_subdir / "1_synthesis_output" / "*/eval_ready_theories"))

        refinement_dir = gen_dir / "refinement"
        cmd_refine = [
            "python", "run_m3_auto_refinement.py",
            "--summary_file", str(summary_file),
            "--theories_root", str(theories_root),
            "--output_dir", str(refinement_dir),
            "--top_n", str(args.top_n),
            "--eval_mode", "real",
            "--max_iters", str(args.max_iters),
            "--min_improve", str(args.min_improve),
            "--judge_model_source", args.evaluation_model_source,
            "--judge_model_name", args.evaluation_model_name,
            "--dialog_model_source", args.evaluation_model_source,
            "--dialog_model_name", args.evaluation_model_name
        ]
        run_cmd(cmd_refine)

        depth_runs_dir = refinement_dir / next(iter((refinement_dir).iterdir())) / "depth_output/depth_runs"
        if not depth_runs_dir.exists():
            depth_runs_dir = refinement_dir / "depth_output/depth_runs"
        improved_pool = gen_dir / "improved_theories_pool"
        collect_improved_theories(depth_runs_dir, improved_pool)

        # ä¸‹ä»£ç†è®ºæ± ï¼šä½¿ç”¨æ”¹å†™ç‰ˆæœ¬ + åŸç†è®º
        theories_dir_for_next = improved_pool
        print(f"[GENERATION {gen}] å°† {len(list(improved_pool.glob('*.json')))} ä¸ªæ”¹å†™ç†è®ºä½œä¸ºä¸‹ä¸€è½®è¾“å…¥ã€‚")
        time.sleep(1)  # ç®€è¦åœé¡¿ï¼Œä¾¿äºæŸ¥çœ‹æ—¥å¿—

    print("\nğŸ‰ å¤šä»£å¾ªç¯å®Œæˆï¼Œæ‰€æœ‰ç»“æœä½äº:", base_root)


if __name__ == "__main__":
    main() 